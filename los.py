# -*- coding: utf-8 -*-
"""LOS

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AP5BmFfH1TMzfTiqpxxbwGtg-PxYfe78
"""

!pip install catboost

import numpy as np
import pandas as pd

from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_absolute_error

from sklearn.metrics import mean_squared_error, r2_score


from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler


import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.svm import LinearSVR, SVR
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from catboost import CatBoostRegressor

data = pd.read_csv('/content/drive/MyDrive/makogr/predict lenght hospital/microsoft dataset/LengthOfStay.csv')

data.head()

data

data.info()

data.isnull().sum()

# 'discharged'  'vdate'
data = data.drop(columns=['discharged', 'vdate'])

# Label Encoding: gender and facid
label_encoder = LabelEncoder()
data['gender'] = label_encoder.fit_transform(data['gender'])
data['facid'] = label_encoder.fit_transform(data['facid'])

# One-Hot Encoding
data = pd.get_dummies(data, columns=['rcount'], prefix='rcount')

data.head()

data['lengthofstay'].describe()

"""Data Visualization"""

plt.figure(figsize=(8, 6))
sns.histplot(data['lengthofstay'], bins=30, kde=True)
plt.title("Hedef Değişken - Length of Stay (Hastanede Kalış Süresi) Dağılımı")
plt.xlabel("Length of Stay - Hastanede Kalış Süresi")
plt.ylabel("Frekans")
plt.show()

disease_columns = [
    'dialysisrenalendstage', 'asthma', 'irondef', 'pneum', 'substancedependence',
    'psychologicaldisordermajor', 'depress', 'psychother', 'fibrosisandother',
    'malnutrition', 'hemo'
]

disease_counts = data[disease_columns].sum().sort_values(ascending=False)

plt.figure(figsize=(12, 6))
sns.barplot(x=disease_counts.index, y=disease_counts.values)
plt.title("Her Hastalığın Frekans Dağılımı")
plt.xlabel("Hastalıklar")
plt.ylabel("Frekans")
plt.xticks(rotation=90)
plt.show()

plt.figure(figsize=(10, 6))
sns.countplot(x='gender', data=data)
plt.title('Cinsiyet Dağılımı')
plt.show()

gender_counts = data['gender'].value_counts()
plt.figure(figsize=(8, 6))
gender_counts.plot.pie(autopct='%1.1f%%', startangle=90, colors=["red", "blue"])
plt.title("Cinsiyet Dağılımı (Pie Chart)")
plt.ylabel('')
plt.show()

plt.figure(figsize=(8, 6))
sns.boxplot(x='gender', y='lengthofstay', data=data)
plt.title("Cinsiyet ve Hastanede Kalış Süresi Arasındaki İlişki")
plt.xlabel("Cinsiyet")
plt.ylabel("Length of Stay (Hastanede Kalış Süresi)")
plt.show()



print(correlation_matrix['lengthofstay'].sort_values(ascending=False))

threshold = 0.2
highly_correlated_features = correlation_matrix['lengthofstay'][abs(correlation_matrix['lengthofstay']) > threshold].index.tolist()


filtered_correlation_matrix = correlation_matrix.loc[high_correlation_columns, high_correlation_columns]


plt.figure(figsize=(8, 6))
sns.heatmap(filtered_correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.1)
plt.title("lengthofstay ile Yüksek Korelasyonlu Özellikler")
plt.show()

X = data.drop('lengthofstay', axis=1)

y = data['lengthofstay']  # target value

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


print(f"Eğitim seti boyutu: {X_train.shape}")
print(f"Test seti boyutu: {X_test.shape}")

lr_model = LinearRegression()

lr_model.fit(X_train, y_train)

lr_y_pred = lr_model.predict(X_test)

lr_mae = mean_absolute_error(y_test, lr_y_pred)
lr_mse = mean_squared_error(y_test, lr_y_pred)
lr_rmse = mean_squared_error(y_test, lr_y_pred, squared=False)
lr_r2 = r2_score(y_test, lr_y_pred)

print(f"Linear Regression -Mean Absolute Error: {lr_mae}")
print(f"Linear Regression -Mean Squared Error: {lr_mse}")
print(f"Linear Regression -Root Mean Squared Error: {lr_rmse}")
print(f"Linear Regression -R-squared: {lr_r2}")

# KNN
knn_model = KNeighborsRegressor()

knn_model.fit(X_train, y_train)
knn_y_pred = knn_model.predict(X_test)

knn_mae = mean_absolute_error(y_test, knn_y_pred)
knn_mse = mean_squared_error(y_test, knn_y_pred)
knn_r2 = r2_score(y_test, knn_y_pred)

print(f"KNN - Mean Absolute Error: {knn_mae}")
print(f"KNN - Mean Squared Error: {knn_mse}")
print(f"KNN - R^2 Score: {knn_r2}")

# Random Forest
rf_model = RandomForestRegressor(random_state=123)
rf_model.fit(X_train, y_train)
rf_y_pred = rf_model.predict(X_test)

rf_mae = mean_absolute_error(y_test, rf_y_pred)
rf_mse = mean_squared_error(y_test, rf_y_pred)
rf_r2 = r2_score(y_test, rf_y_pred)


print(f"Random Forest - Mean Absolute Error: {rf_mae}")
print(f"Random Forest - Mean Squared Error: {rf_mse}")
print(f"Random Forest - R^2 Score: {rf_r2}")

# Gradient Boosting Regressor
gbr_model = GradientBoostingRegressor(random_state=123)
gbr_model.fit(X_train, y_train)
gbr_y_pred = gbr_model.predict(X_test)

gbr_mae = mean_absolute_error(y_test, gbr_y_pred)
gbr_mse = mean_squared_error(y_test, gbr_y_pred)
gbr_r2 = r2_score(y_test, gbr_y_pred)

print(f"Gradient Boosting Regressor - Mean Absolute Error: {gbr_mae}")
print(f"Gradient Boosting Regressor - Mean Squared Error: {gbr_mse}")
print(f"Gradient Boosting Regressor - R^2 Score: {gbr_r2}")

# Support Vector Regressor
svr_model = SVR()
svr_model.fit(X_train, y_train)
svr_y_pred = svr_model.predict(X_test)

svr_mse = mean_squared_error(y_test, svr_y_pred)
svr_r2 = r2_score(y_test, svr_y_pred)
svr_mae = mean_absolute_error(y_test, svr_y_pred)

print(f"Support Vector Regressor - Mean Absolute Error: {svr_mae}")
print(f"Support Vector Regressor - Mean Squared Error: {svr_mse}")
print(f"Support Vector Regressor - R^2 Score: {svr_r2}")

# CatBoost Regressor
catboost_model = CatBoostRegressor(verbose=0, random_state=123)
catboost_model.fit(X_train, y_train)
catboost_y_pred = catboost_model.predict(X_test)

catboost_mse = mean_squared_error(y_test, catboost_y_pred)
catboost_r2 = r2_score(y_test, catboost_y_pred)
catboost_mae = mean_absolute_error(y_test, catboost_y_pred)


print(f"CatBoost - Mean Absolute Error: {catboost_mae}")
print(f"CatBoost - Mean Squared Error: {catboost_mse}")
print(f"CatBoost - R^2 Score: {catboost_r2}")

# XGBoost Regressor
xgb_model = XGBRegressor(random_state=123)
xgb_model.fit(X_train, y_train)
xgb_y_pred = xgb_model.predict(X_test)

xgb_mse = mean_squared_error(y_test, xgb_y_pred)
xgb_r2 = r2_score(y_test, xgb_y_pred)
xgb_mae = mean_absolute_error(y_test, xgb_y_pred)

print(f"XGBoost - Mean Absolute Error: {xgb_mae}")
print(f"XGBoost - Mean Squared Error: {xgb_mse}")
print(f"XGBoost - R^2 Score: {xgb_r2}")

# Model tahminlerini kontrol edelim

print(f"Linear Regression - Metrikler: {lr_mse}, {lr_r2}")
print(f"KNN - Metrikler: {knn_mse}, {knn_r2}")
print(f"Random Forest - Metrikler: {rf_mse}, {rf_r2}")
print(f"Gradient Boosting - Metrikler: {gbr_mse}, {gbr_r2}")
print(f"CatBoost - Metrikler: {catboost_mse}, {catboost_r2}")
print(f"SVR - Metrikler: {svr_mse}, {svr_r2}")
print(f"XGB - Metrikler: {xgb_mse}, {xgb_r2}")

results = {
    "Model": ["Linear Regression", "KNN", "Random Forest", "Gradient Boosting", "SVR", "CatBoost", "XGBoost"],
    "MAE":[ lr_mae, knn_mae, rf_mae, gbr_mae, svr_mae, catboost_mae, xgb_mae],
    "MSE": [ lr_mse, knn_mse, rf_mse, gbr_mse, svr_mse,catboost_mse, xgb_mse] ,
    "R^2": [ lr_r2, knn_r2, rf_r2, gbr_r2,  svr_r2, catboost_r2, xgb_r2]

}

results_df = pd.DataFrame(results)
print(results_df)



!pip install boruta

from boruta import BorutaPy

rf = RandomForestRegressor(random_state=42, n_jobs=-1)
boruta = BorutaPy(estimator=rf, n_estimators='auto', random_state=42)


boruta.fit(X_train.values, y_train.values)

selected_features_boruta = X_train.columns[boruta.support_].tolist()
print(f"Seçilen Özellikler (Boruta): {selected_features_boruta}")

X_train_boruta = X_train[selected_features_boruta]
X_test_boruta = X_test[selected_features_boruta]

svr_model = SVR()

svr_model.fit(X_train_boruta, y_train)
svr_y_pred = svr_model.predict(X_test_boruta)

svr_mse = mean_squared_error(y_test, svr_y_pred)
svr_r2 = r2_score(y_test, svr_y_pred)
svr_mae = mean_absolute_error(y_test, svr_y_pred)

print(f"Support Vector Regressor - Mean Absolute Error: {svr_mae}")
print(f"Support Vector Regressor - Mean Squared Error: {svr_mse}")
print(f"Support Vector Regressor - R^2 Score: {svr_r2}")

from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score


gb_model = GradientBoostingRegressor(random_state=42)

gb_model.fit(X_train[selected_features_boruta], y_train)

gb_y_pred = gb_model.predict(X_test[selected_features_boruta])

gb_mae = mean_absolute_error(y_test, gb_y_pred)
gb_mse = mean_squared_error(y_test, gb_y_pred)
gb_r2 = r2_score(y_test, gb_y_pred)

print(f"Gradient Boosting - MAE: {gb_mae}")
print(f"Gradient Boosting - MSE: {gb_mse}")
print(f"Gradient Boosting - R^2: {gb_r2}")

from catboost import CatBoostRegressor

catboost_model = CatBoostRegressor(random_state=42, iterations=1000, learning_rate=0.1, depth=6, verbose=0)

catboost_model.fit(X_train[selected_features_boruta], y_train)

catboost_y_pred = catboost_model.predict(X_test[selected_features_boruta])

catboost_mae = mean_absolute_error(y_test, catboost_y_pred)
catboost_mse = mean_squared_error(y_test, catboost_y_pred)
catboost_r2 = r2_score(y_test, catboost_y_pred)

print(f"CatBoost - MAE: {catboost_mae}")
print(f"CatBoost - MSE: {catboost_mse}")
print(f"CatBoost - R^2: {catboost_r2}")

models = {
    'Linear Regression': LinearRegression(),
    'Random Forest': RandomForestRegressor(),
    'Gradient Boosting': GradientBoostingRegressor(),
    'CatBoost': CatBoostRegressor(iterations=1000, learning_rate=0.1, depth=10, verbose=0),
    'SVR': SVR(),
    'XGB': XGBRegressor(objective='reg:squarederror', random_state=42)
}

results = {}
for model_name, model in models.items():

    model.fit(X_train, y_train)


    y_pred = model.predict(X_test)


    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)


    results[model_name] = {
        'MAE': mae,
        'MSE': mse,
        'R2': r2
    }


results_df = pd.DataFrame(results).T
print(results_df)

best_model = results_df['R2'].idxmax()
print(f'En iyi model: {best_model}')